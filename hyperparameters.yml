# HYPERPARAMETERS TEMPLATE
# THIS FILE IS A TEMPLATE AND SHOULD NOT BE USED DIRECTLY

# ENVIRONMENT PARAMETERS
ENV_NAME: # Name of the environment

# ARCHITECTURE PARAMETERS
ACTOR_HIDDEN_LAYERS: [] # Hidden Layers for Actor. Don't include the input and output layer
CRITIC_HIDDEN_LAYERS: [] # Hidden Layers for Critic. Don't include the input and output layer

# TRAINING PARAMETERS
ACTOR_LR: 3e-4 # Actor Learning Rate
CRITIC_LR: 3e-4 # Critic Learning Rate
ALPHA_LR: 3e-4 # Alpha Learning Rate

# SAC ALGORITHM PARAMETERS
GAMMA: 0.99 # Determines how much future rewards matter
TAU: 0.001 # How much to move target network toward actual network
TARGET_ALPHA: 1 # Ideal goal for the weight of the entropy

# ACTOR NETWORK PARAMETERS
STD_CLAMP_MIN: -5 # Minimum value of the standard deviation values of the output
STD_CLAMP_MAX: 2 # Maximum value of the standard deviation values of the output

# EXPERIENCE REPLAY PARAMETERS
NUM_EPOCHS: 1000 # Number of training runs to do
BATCH_SIZE: 64 # Number of experiences to train on during training step
TRAINING_START_STEP: 1000 # Minimum number of experiences needed to start training, must be greater than batch size
EXPERIENCE_REPLAY_LENGTH: 300000 # Size of the experience array

# LOGGING AND TESTING PARAMETERS
LOGGING_FREQUENCY: 10 # How often to test the agent and print stats
SLIDING_WINDOW_SIZE: 50 # Size of the sliding window of the rewards to get average
FILE_NAME: '' # General File Name - string of path to file
NUM_TESTS: 100 # Number of tests